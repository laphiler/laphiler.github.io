<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">
<!-- Font-Awesome -->
<link rel="stylesheet" href="<%- url_for('/font-awesome-4.7.0/css/font-awesome.min.css') %>">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5">


  <link rel="mask-icon" href="/images/logo.svg?v=5" color="#222">





  <meta name="keywords" content="AI,Deep learning,CNN,YoLo,SSD,Object detection," />










<meta name="description" content="目标检测是计算机视觉领域一个经典问题，上一篇介绍了基于region proposal的深度学习系列模型，本篇介绍基于回归方法的深度学习目标检测模型YoLo，YoLov2，SSD。">
<meta name="keywords" content="AI,Deep learning,CNN,YoLo,SSD,Object detection">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN经典神经网络模型 | 目标检测(续)">
<meta property="og:url" content="http://laphiler.com/2018/01/15/cnn-classic-model-objectdetection2/index.html">
<meta property="og:site_name" content="Laphiler">
<meta property="og:description" content="目标检测是计算机视觉领域一个经典问题，上一篇介绍了基于region proposal的深度学习系列模型，本篇介绍基于回归方法的深度学习目标检测模型YoLo，YoLov2，SSD。">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_classic_model%2Fmodel_compare.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_detection_sys.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLov1-arch.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_inference.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_2_boxes.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-loss.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-loss-1.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-test-1.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-test-2.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-model.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FVGG_model.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd_box.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-model-detail.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd_loss.png@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-positive-sample.jpg@!laphiler">
<meta property="og:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-default-box.png@!laphiler">
<meta property="og:updated_time" content="2018-01-18T10:36:35.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN经典神经网络模型 | 目标检测(续)">
<meta name="twitter:description" content="目标检测是计算机视觉领域一个经典问题，上一篇介绍了基于region proposal的深度学习系列模型，本篇介绍基于回归方法的深度学习目标检测模型YoLo，YoLov2，SSD。">
<meta name="twitter:image" content="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_classic_model%2Fmodel_compare.png@!laphiler">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://laphiler.com/2018/01/15/cnn-classic-model-objectdetection2/"/>





  <title>CNN经典神经网络模型 | 目标检测(续) | Laphiler</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Laphiler</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Wars come and go, but my soldiers stay eternal.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://laphiler.com/2018/01/15/cnn-classic-model-objectdetection2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Laphiler Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/laphiler.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Laphiler">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CNN经典神经网络模型 | 目标检测(续)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-15T21:44:09+08:00">
                2018-01-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>目标检测是计算机视觉领域一个经典问题，<a href="http://www.laphiler.com/2018/01/08/cnn-classic-model-objectdetection/" target="_blank" rel="noopener">上一篇介绍了基于region proposal的深度学习系列模型</a>，本篇介绍基于回归方法的深度学习目标检测模型YoLo，YoLov2，SSD。</p>
<a id="more"></a>
<p>paper:</p>
<ul>
<li><a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">YoLo - You Only Look Once: Unified, Real-Time Object Detection</a> (2015)</li>
<li><a href="https://arxiv.org/abs/1709.05943" target="_blank" rel="noopener">YoLov2 - Fast YOLO: A Fast You Only Look Once System for Real-time Embedded Object Detection in Video
</a></li>
<li><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO9000 - YOLO9000: Better, Faster, Stronger</a> (2016)</li>
<li><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">SSD: Single Shot MultiBox Detector
</a> (2016)</li>
</ul>
<p>code:</p>
<ul>
<li><a href="https://github.com/choasUp/caffe-yolo9000" target="_blank" rel="noopener">caffe实现：caffe-yolo9000</a></li>
<li><a href="https://github.com/weiliu89/caffe/tree/ssd" target="_blank" rel="noopener">caffe实现：ssd</a></li>
</ul>
<h2 id="YoLo"><a href="#YoLo" class="headerlink" title="YoLo"></a>YoLo</h2><h3 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h3><p>YOLO将物体检测作为回归问题求解。基于一个单独的end-to-end网络，完成从原始图像的输入到物体位置和类别的输出。从网络设计上，YOLO与rcnn、fast rcnn及faster rcnn的区别如下：</p>
<ul>
<li><p><strong>YOLO训练和检测均是在一个单独网络中进行，实现真正意义上的端到端的模型。</strong>YOLO没有显示地求取region proposal的过程。而rcnn/fast rcnn 采用分离的模块（独立于网络之外的selective search方法）求取候选框（可能会包含物体的矩形区域），训练过程因此也是分成多个模块进行。Faster rcnn使用RPN（region proposal network）卷积网络替代rcnn/fast rcnn的selective<br>search模块，将RPN集成到fast rcnn检测网络中，得到一个统一的检测网络。尽管RPN与fast rcnn共享卷积层，但是在模型训练过程中，需要反复训练RPN网络和fast rcnn网络（注意这两个网络核心卷积层是参数共享的）</p>
</li>
<li><p><strong>YOLO将物体检测作为一个回归问题进行求解</strong>，输入图像经过一次inference，便能得到图像中所有物体的位置和其所属类别及相应的置信概率。而rcnn/fast rcnn/faster rcnn将检测结果分为两部分求解：物体类别（分类问题），物体位置即bounding box（回归问题）。</p>
</li>
</ul>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_classic_model%2Fmodel_compare.png@!laphiler" alt=""></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><ul>
<li>YOLO网络借鉴了GoogLeNet分类网络结构。不同的是，YOLO未使用Inception Module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+ 3x3卷积层简单替代。</li>
<li>Fast YOLO使用9个卷积层代替YOLO的24个，网络更轻快，速度从YOLO的45fps提升到155fps，但同时损失了检测准确率。</li>
<li>使用全图作为 Context 信息，背景错误（把背景错认为物体）比较少。</li>
</ul>
<p><strong>流程</strong></p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_detection_sys.png@!laphiler" alt=""></p>
<ol>
<li>Resize成448x448，图片分割得到7x7网格(cell)</li>
<li>CNN提取特征和预测：卷积不忿负责提特征。全链接部分负责预测：<ul>
<li>a) 7x7x2=98个bounding box(bbox) 的坐标x<em>{center},y</em>{center},w,h 以及是否有物体的conﬁdence共5个值。</li>
<li>b) 7x7=49个cell所属20个物体的概率。</li>
</ul>
</li>
<li>过滤bbox（通过nms）</li>
</ol>
<p>YOLO检测网络包括24个卷积层和2个全连接层，如下图所示。其中，<strong>卷积层用来提取图像特征</strong>，<strong>全连接层用来预测图像位置和类别概率值</strong>。</p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLov1-arch.png@!laphiler" alt=""></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ol>
<li><strong>预训练分类网络</strong>： 在 ImageNet 1000-class competition dataset上预训练一个分类网络，这个网络是上图中的前20个卷机网络+average-pooling layer+ fully connected layer （此时网络输入是224x224）。</li>
<li>训练检测网络：转换模型去执行检测任务，《Object detection networks on convolutional feature maps》提到说在预训练网络中增加卷积和全链接层可以改善性能。在他们例子基础上添加4个卷积层和2个全链接层，随机初始化权重。检测要求细粒度的视觉信息，所以把网络输入也又224x224变成448x448。见上图。 </li>
</ol>
<h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_inference.png@!laphiler" alt=""></p>
<p><a href="https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g137784ab86_4_4011" target="_blank" rel="noopener">详细过程参考Google doc</a></p>
<ul>
<li>一幅图片分成 <span>$7*7$</span><!-- Has MathJax --> 个网格(grid cell)，某个物体的中心落在这个网格中此网格就负责预测这个物体。</li>
<li><p>最后一层输出为 <span>$(7 * 7) * 30$</span><!-- Has MathJax --> 的维度。每个 <span>$1 * 1 * 30$</span><!-- Has MathJax --> 的维度对应原图 <span>$7 * 7$</span><!-- Has MathJax --> 个cell中的一个，<span>$1 * 1 * 30$</span><!-- Has MathJax --> 中含有类别预测和bbox坐标预测。</p>
<ol>
<li><p>a) 每个网格（ <span>$1 * 1 * 30$</span><!-- Has MathJax --> 维度对应原图中的cell）要预测<strong>2个bounding box</strong> （下图中<strong>黄色实线框</strong>）的坐标 <span>$（x_{center},y_{center},w,h）$</span><!-- Has MathJax --> ，其中：中心坐标的 <span>$x_{center},y_{center}$</span><!-- Has MathJax --> 相对于对应的网格归一化到0-1之间，w,h用图像的width和height归一化到0-1之间。 每个bounding box除了要回归自身的位置之外，还要附带预测一个 <span>$confidence$</span><!-- Has MathJax --> 值。 这个<strong>confidence</strong>代表了所预测的box中<strong>含有object的置信度</strong>和<strong>这个box预测的有多准两重信息</strong>： <span>$confidence = Pr(Object) * IOU^{truth}_{pred}$</span><!-- Has MathJax --> 其中如果有ground true box(人工标记的物体)落在一个grid cell里，第一项取1，否则取0。 第二项是预测的bounding box和实际的ground truth box之间的IoU值。即：每个bounding box要预测 <span>$x_{center},y_{center},w,h,confidence$</span><!-- Has MathJax --> 共5个值 ，2个bounding box共10个值，对应 <span>$1 * 1 * 30$</span><!-- Has MathJax --> 维度特征中的前10个。</p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo_2_boxes.png@!laphiler" alt=""></p>
</li>
<li><p>b) 每个网格还要预测<strong>类别信息</strong>，论文中有20类。<span>$7 * 7$</span><!-- Has MathJax --> 的网格，每个网格要预测2个 bounding box 和 20个类别概率，输出就是 <span>$7 * 7 * (5 * 2 + 20)$</span><!-- Has MathJax --> 。 (通用公式： SxS个网格，每个网格要预测B个bounding box还要预测C个categories，输出就是<span>$S * S * (5 * B + C)$</span><!-- Has MathJax --> 的一个tensor。 注意：class信息是针对每个网格的，confidence信息是针对每个bounding box的）</p>
</li>
</ol>
</li>
</ul>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>损失函数的定义如下，损失函数的设计目标就是让坐标，置信度和类别这个三个方面达到很好的平衡。简单的全部采用了Sum-Squared Error Loss来做这件事会有以下不足：① 8维的Localization Error和20维的Classification Error同等重要显然是不合理的；② 如果一个网格中没有Object（一幅图中这种网格很多），那么就会将这些网格中的Box的Confidence Push到0，相比于较少的有Object的网格，这种做法是Overpowering的，这会导致网络不稳定甚至发散。 解决方案如下。<a href="http://lanbing510.info/2017/08/28/YOLO-SSD.html" target="_blank" rel="noopener">参考原文</a></p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-loss.png@!laphiler" alt=""></p>
<ol>
<li>更重视8维的坐标预测，给这些损失前面赋予更大的Loss Weight, 记为 <span>$&lambda;_{coord}$</span><!-- Has MathJax --> ,在Pascal VOC训练中取5。（上图蓝色框）。</li>
<li>对没有Object的Bbox的Confidence Loss，赋予小的Loss Weight，记为<br><span>$&lambda;_{noobj}$</span><!-- Has MathJax --> 在Pascal VOC训练中取0.5上图橙色框）。</li>
<li>有Object的Bbox的Confidence Loss（上图红色框）和类别的Loss（上图紫色框）的Loss Weight正常取1。</li>
<li>对不同大小的Bbox预测中，相比于大Bbox预测偏一点，小Bbox预测偏一点更不能忍受。而Sum-Square Error Loss中对同样的偏移Loss是一样。为了缓和这个问题，将Bbox的Width和Height取平方根代替原本的Height和Width。 如下图：Small Bbox的横轴值较小，发生偏移时，反应到y轴上的Loss（下图绿色）比Big Bbox（下图红色）要大。</li>
<li>一个网格预测多个Bbox，在训练时我们希望每个Object（Ground True box）只有一个Bbox专门负责（一个Object 一个Bbox）。具体做法是与Ground True Box（Object）的IOU最大的Bbox 负责该Ground True Box（Object）的预测。这种做法称作Bbox Predictor的Specialization（专职化）。每个预测器会对特定（Sizes,Aspect Ratio or Classed of Object）的Ground True Box预测的越来越好。</li>
</ol>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-loss-1.png@!laphiler" alt=""></p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>计算每个Bbox的Class-Specific Confidence Score：每个网格预测的Class信息(<br><span>$Pr(Class_i|Object))$</span><!-- Has MathJax --> 和Bbox预测的Confidence信息 <span>$(Pr(Object) &lowast; IOU^{truth}_{pred})$</span><!-- Has MathJax --> 相乘，就得到每个Bbox的Class-Specific Confidence Score。<br><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-test-1.png@!laphiler" alt=""></p>
<p>2 进行Non-Maximum Suppression（NMS）：得到每个Bbox的Class-Specific Confidence Score以后，设置阈值，滤掉得分低的Bboxes，对保留的Bboxes进行NMS处理，就得到最终的检测结果。更为直观详细的流程可参见[5]。<br><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FYoLo-test-2.png@!laphiler" alt=""></p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>YOLO对相互靠的很近的物体（挨在一起且中点都落在同一个格子上的情况），还有很小的群体 检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类。</li>
<li>测试图像中，当同一类物体出现的不常见的长宽比和其他情况时泛化能力偏弱。</li>
<li>由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。</li>
</ul>
<h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p>上半部分介绍的YoLo有一些缺陷：每个网格只预测一个物体，容易造成漏检；对于物体的尺度相对比较敏感，对于尺度变化较大的物体泛化能力较差。针对这两个方面SSD都有所改进，同时兼顾了 mAP 和实时性的要求（见本文开始的图1，几个模型对比）。在满足实时性的条件下，接近state of art的结果。作者的思路就是Faster R-CNN+YOLO，利用YOLO的思路和Faster R-CNN的anchor box的思想。<a href="http://blog.csdn.net/u010167269/article/details/52563573" target="_blank" rel="noopener">参考</a></p>
<h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-model.png@!laphiler" alt=""></p>
<p>该论文采用 VGG16 的基础网络结构(作者用的是D这个模型进行修改的)，使用前面的前 5 层，然后利用 astrous 算法将 fc6 和 fc7 层转化成两个卷积层。再格外增加了 3 个卷积层，和一个 average pool层。不同层次的 feature map 分别用于 default box 的偏移以及不同类别得分的预测（惯用思路：使用通用的结构(如前5个conv等)作为基础网络，然后在这个基础上增加其他的层），最后通过nms得到最终的检测结果。</p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2FVGG_model.png@!laphiler" alt=""></p>
<p><strong>总结一下</strong>，SSD 模型的最开始部分，本文称作 base network，是用于图像分类的标准架构。在 base network 之后，本文添加了额外辅助的网络结构：</p>
<ul>
<li><strong>Multi-scale feature maps for detection</strong><br>在基础网络结构后，添加了额外的卷积层，这些卷积层的大小是逐层递减的，可以在多尺度下进行 predictions。</li>
<li><strong>Convolutional predictors for detection</strong><br>每一个添加的特征层（或者在基础网络结构中的特征层），可以使用一系列 convolutional filters，去产生一系列固定大小的 <strong>predictions</strong>，具体见 Fig.2。对于一个大小为 <span>$m&times;n$</span><!-- Has MathJax -->，具有 <span>$p$</span><!-- Has MathJax --> 通道的feature map层，使用的 convolutional filters 就是 <span>$3&times;3&times;p$</span><!-- Has MathJax --> 的 kernels。产生的 predictions，那么就是归属类别的一个得分，要么就是相对于 default box coordinate 的 shape offsets。<br>在每一个 <span>$m&times;n$</span><!-- Has MathJax --> 的特征图位置上，使用上面的 3×3 的 kernel，会产生一个输出值。<strong>bounding box offset</strong> 值是输出的 default box 与此时 feature map location 之间的相对距离（YOLO 架构则是用一个全连接层来代替这里的卷积层）。</li>
<li><strong>Default boxes and aspect ratios</strong><br>每一个 box 相对于与其对应的 feature map cell 的位置是固定的。 在每一个 feature map cell 中，我们要 predict 得到的 box 与 default box 之间的 offsets，以及每一个 box 中包含物体的 score（每一个类别概率都要计算出）。<br>因此，对于一个位置上的 <span>$k$</span><!-- Has MathJax --> 个boxes 中的每一个 box，我们需要计算出 c 个类，每一个类的 score，还有这个 box 相对于 它的默认 box 的 <span>$4$</span><!-- Has MathJax --> 个偏移值（offsets）。于是，在 feature map 中的每一个 feature map cell 上，就需要有 <span>$(c+4)&times;k$</span><!-- Has MathJax --> 个 filters。对于一张 <span>$m&times;n$</span><!-- Has MathJax --> 大小的 feature map，即会产生 <span>$(c+4)&times;k&times;m&times;n$</span><!-- Has MathJax --> 个输出结果。</li>
</ul>
<h4 id="default-boxes-amp-feature-map-cell"><a href="#default-boxes-amp-feature-map-cell" class="headerlink" title="default boxes &amp; feature map cell"></a>default boxes &amp; feature map cell</h4><ul>
<li><strong>feature map cell</strong>就是将<strong>feature map</strong>切分成 8×8 或者 4×4 之后的一个个格子；</li>
<li>而<strong>default box</strong>就是每一个格子上，一系列固定大小的 box，即图中虚线所形成的一系列 boxes。</li>
</ul>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd_box.png@!laphiler" alt=""></p>
<h4 id="模型flow"><a href="#模型flow" class="headerlink" title="模型flow"></a>模型flow</h4><p>这些增加的卷积层的 feature map 的大小变化比较大，允许能够检测出不同尺度下的物体： 在低层的feature map,感受野比较小，高层的感受野比较大，在不同的feature map进行卷积，可以达到多尺度的目的。观察YoLo，后面存在两个全连接层，全连接层以后，每一个输出都会观察到整幅图像，并不是很合理。但是SSD去掉了全连接层，每一个输出只会感受到目标周围的信息，包括上下文。这样来做就增加了合理性。并且不同的feature map,预测不同宽高比的图像，这样比YOLO增加了预测更多的比例的box。（下图横向的流程）</p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-model-detail.png@!laphiler" alt=""></p>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><p>这个与Faster R-CNN中的RPN是一样的，不过RPN是预测box里面有object或者没有，所以，没有分类，SSD直接用的softmax分类。location的损失，还是一样，都是用predict box和default box/Anchor的差 与 ground truth box和default box/Anchor的差 进行对比，求损失。</p>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd_loss.png@!laphiler" alt=""></p>
<h4 id="训练策略"><a href="#训练策略" class="headerlink" title="训练策略"></a>训练策略</h4><p>监督学习的训练关键是人工标注的label。对于包含default box(在Faster R-CNN中叫做anchor)的网络模型（如： YOLO,Faster R-CNN, MultiBox）关键点就是如何把 标注信息(ground true box,ground true category)映射到（default box上）</p>
<ul>
<li>正负样本： 给定输入图像以及每个物体的 ground truth,首先找到每个ground true box对应的default box中IOU最大的作为（与该ground true box相关的匹配）正样本。然后，在剩下的default box中找到那些与任意一个ground truth box 的 IOU 大于 0.5的default box作为（与该ground true box相关的匹配）正样本。 一个 ground truth 可能对应多个 正样本default box 而不再像MultiBox那样只取一个IOU最大的default box。其他的作为负样本（每个default box要么是正样本box要么是负样本box）。下图的例子是：给定输入图像及 ground truth，分别在两种不同尺度(feature map 的大小为 8 <em> 8，4 </em> 4)下的匹配情况。有两个 default box 与猫匹配（8 <em> 8），一个 default box 与狗匹配（4 </em> 4）。</li>
</ul>
<p><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-positive-sample.jpg@!laphiler" alt=""></p>
<p>该论文是在 ImageNet 分类和定位问题上的已经训练好的 VGG16 模型中 fine-tuning 得到，使用 SGD，初始学习率为 <span>$10^{-3}$</span><!-- Has MathJax -->, 冲量为 0.9，权重衰减为 0.0005，batchsize 为 32。不同数据集的学习率改变策略不同。新增加的卷积网络采用 xavier 的方式进行初始化</p>
<ul>
<li>Default Box 的生成：<br><img src="http://xiaoluban.cdn.bcebos.com/laphiler%2FCNN_object_detection2%2Fssd-default-box.png@!laphiler" alt=""></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/AI/" rel="tag"># AI</a>
          
            <a href="/tags/Deep-learning/" rel="tag"># Deep learning</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/YoLo/" rel="tag"># YoLo</a>
          
            <a href="/tags/SSD/" rel="tag"># SSD</a>
          
            <a href="/tags/Object-detection/" rel="tag"># Object detection</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/14/cnn-ssd-caffe-md/" rel="next" title="SSD的caffe实现">
                <i class="fa fa-chevron-left"></i> SSD的caffe实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/26/mask-rcnn/" rel="prev" title="Mask R-CNN原理与Mask R-CNN2Go介绍">
                Mask R-CNN原理与Mask R-CNN2Go介绍 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/laphiler.png"
                alt="Laphiler Zhang" />
            
              <p class="site-author-name" itemprop="name">Laphiler Zhang</p>
              <p class="site-description motion-element" itemprop="description">Wars come and go, but my soldiers stay eternal.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/laphiler" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:laphiler@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://twitter.com/laphiler" target="_blank" title="Twitter">
                    
                      <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#YoLo"><span class="nav-number">1.</span> <span class="nav-text">YoLo</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创新"><span class="nav-number">1.1.</span> <span class="nav-text">创新</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构"><span class="nav-number">1.2.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-number">1.3.</span> <span class="nav-text">训练</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#具体过程"><span class="nav-number">1.3.1.</span> <span class="nav-text">具体过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数"><span class="nav-number">1.3.2.</span> <span class="nav-text">损失函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试"><span class="nav-number">1.4.</span> <span class="nav-text">测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺点"><span class="nav-number">1.5.</span> <span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SSD"><span class="nav-number">2.</span> <span class="nav-text">SSD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构-1"><span class="nav-number">2.1.</span> <span class="nav-text">网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#default-boxes-amp-feature-map-cell"><span class="nav-number">2.1.1.</span> <span class="nav-text">default boxes & feature map cell</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型flow"><span class="nav-number">2.1.2.</span> <span class="nav-text">模型flow</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练-1"><span class="nav-number">2.2.</span> <span class="nav-text">训练</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练策略"><span class="nav-number">2.2.2.</span> <span class="nav-text">训练策略</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Laphiler Zhang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5</div>


<!--统计start-->
<div class="busuanzi-count">
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
</div>
<!--统计end-->



        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
